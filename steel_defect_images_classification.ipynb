{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "steel_defect_images_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysforgithub/steel_defects_detection_classification/blob/master/steel_defect_images_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2713DYqrP21K",
        "colab_type": "text"
      },
      "source": [
        "**The Data source of this notebook is based on https://www.kaggle.com/c/severstal-steel-defect-detection/data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pgM29Z2osFp",
        "colab_type": "code",
        "outputId": "4d7dc734-08ec-4cb2-9a7a-6a7fa067a583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Get the access of the google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cm6BYKKflKM",
        "colab_type": "code",
        "outputId": "db03e661-fcb0-4b2c-e3af-9dab0025d854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "# Change hge working directory to the training images folder \n",
        "import os\n",
        "import keras\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/kaggle/steel defect/80%_train_images')\n",
        "os.getcwd()\n",
        "os.listdir()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['customer_1.tfrecord',\n",
              " '80%_train_images_label_map.json',\n",
              " 'Class_0',\n",
              " 'Class_1',\n",
              " 'Class_2',\n",
              " 'Class_3',\n",
              " 'Class_4',\n",
              " '80%_train_images_completePixels.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11Zp4mHXdjwj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6b31752a-ab41-4461-9ffe-09880e7eb7ff"
      },
      "source": [
        "# Print out the version of tensorflow to make sure the version is newer than 1.13. \n",
        "# A older tensorflow wouldn't have all the functions we need for this notebook \n",
        "print(tf.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15U1v_9Uh4HX",
        "colab_type": "code",
        "outputId": "145014bb-a0a0-4292-a230-d9498ad08998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Get the training images directory and validation images directory \n",
        "train_dir = os.getcwd()\n",
        "validation_dir = '/content/drive/My Drive/Colab Notebooks/kaggle/steel defect/'+'validation_images'\n",
        "print(\"train_dir:\",train_dir)\n",
        "print('validation_dir:',validation_dir)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_dir: /content/drive/My Drive/Colab Notebooks/kaggle/steel defect/80%_train_images\n",
            "validation_dir: /content/drive/My Drive/Colab Notebooks/kaggle/steel defect/validation_images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnBLahGEjHhy",
        "colab_type": "text"
      },
      "source": [
        "# Define a CNN model to train the images classification "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUETdPqParln",
        "colab_type": "code",
        "outputId": "038555c3-8481-4f58-c075-ea405facc235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def create_model():\n",
        "\n",
        "  return tf.keras.models.Sequential([\n",
        "    # The input shape of the model is (256,1600,3)\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(256,1600, 3),data_format='channels_last'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model = create_model()\n",
        "model.compile(optimizer=Adam(lr=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOwbgJkE1dFn",
        "colab_type": "text"
      },
      "source": [
        "*The summary of the model shows each layer of the CNN*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPoMK5j8aHRC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "outputId": "929f7f95-b124-4a1a-ab8e-8cb6513f3c66"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 254, 1598, 16)     448       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 254, 1598, 16)     64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 127, 799, 16)      0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 127, 799, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 125, 797, 32)      4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 125, 797, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 62, 398, 32)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 62, 398, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 60, 396, 64)       18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 60, 396, 64)       256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 30, 198, 64)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 30, 198, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 28, 196, 128)      73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 28, 196, 128)      512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 98, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 14, 98, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 175616)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               22478976  \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 264       \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 45        \n",
            "=================================================================\n",
            "Total params: 22,581,813\n",
            "Trainable params: 22,581,333\n",
            "Non-trainable params: 480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaPvdjNU3ALS",
        "colab_type": "text"
      },
      "source": [
        "**The image data generator is applied to preprocessing each images with some customized feature,such as rotate image, filp the image orizentally, adjust shear of the image.** \n",
        "\n",
        "*The purpose is to enlarge the dataset for the model training. Due to the lack of RAM in my laptop, I only use one technique of preprocessing: devide each pixel's RBG value by 255 which is the maximumn number of the pixel RGB value, to release some stress from massive model data computing.*\n",
        "\n",
        "**Flow the image data generator through each folder of the training imanges and the validation images. Each folder represents a class of images.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqZu_z5tf1Ds",
        "colab_type": "code",
        "outputId": "3dda67f6-e841-4a88-bf76-1e0d7683066d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Create imagedatagenerator for training images set and validation images set\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "      #rotation_range=40,\n",
        "      #width_shift_range=0.2,\n",
        "      #height_shift_range=0.2,\n",
        "      #shear_range=0.2,\n",
        "      #zoom_range=0.2,\n",
        "      #horizontal_flip=True,\n",
        "      #fill_mode='nearest'\n",
        "                                  )\n",
        "test_datagen = ImageDataGenerator(rescale=1./255,\n",
        "      #rotation_range=40,\n",
        "      #width_shift_range=0.2,\n",
        "      #height_shift_range=0.2,\n",
        "      #shear_range=0.2,\n",
        "      #zoom_range=0.2,\n",
        "      #horizontal_flip=True,\n",
        "      #fill_mode='nearest'\n",
        "                                 )\n",
        "# flow training images in batches of 32 using train_datagen generator \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "  train_dir,\n",
        "  target_size = (256,1600),\n",
        "  color_mode='rgb',\n",
        "  batch_size = 32,\n",
        "  class_mode = 'sparse'\n",
        ")\n",
        "\n",
        "# flow validation images in batches \n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "  validation_dir,\n",
        "  target_size=(256,1600),\n",
        "  color_mode='rgb',\n",
        "  batch_size = 32,\n",
        "  class_mode = 'sparse'\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10397 images belonging to 5 classes.\n",
            "Found 2600 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xt63R-s73bp",
        "colab_type": "text"
      },
      "source": [
        "Define the callback function used during the model training:\n",
        "\n",
        "\n",
        "1.   callback 1: earlystop, this function will stop the model training when the model detect there is no accracy improment between the last two training epoch. The setting of the accuracy difference here is 0.05\n",
        "2.   callback 2: modelcheckpoint, this function will check the accuracy after each epoch of training. Then save the best model's weights to a H5 file based on the loss value of each training. \n",
        "3.   callback 3: tensorboard, this function will log the accuracy, loss info of each epoch then save it as a file. After the training is completed or stopped, launch the tensorboard will be able to visualize the training accuracy and loss curve. \n",
        "4.   callback 4: learning scheduler, this function will adjust the hyperparameter of the training model, lr(learning rate). At the begining of the model training, the learning rate is bigger which means the model's parameters(weigths) will be adjusted more aggresively. Then the learning rate is decreased when the training is getting closer to the end to prevent the model is overfitted. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQfeuL05ZHOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras callbacks\n",
        "import keras, os, datetime\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "k_earlystop = keras.callbacks.EarlyStopping(monitor='acc', min_delta=0.05, patience=1, verbose=0, mode='auto', baselinestore_best_weights=False)\n",
        "\n",
        "k_checkpoint = keras.callbacks.ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/kaggle/steel defect/weights_sets/'+current_time+'_CNN.hdf5', monitor='loss', verbose=1,\n",
        "    save_best_only=True, mode='auto', period=1)\n",
        "\n",
        "log_directory=\"/content/drive/My Drive/Colab Notebooks/kaggle/steel defect/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "k_tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_directory,histogram_freq=0, batch_size=32, write_graph=True, update_freq='epoch')\n",
        "\n",
        "def scheduler(epoch,lr):\n",
        "  if epoch < 10:\n",
        "    pass\n",
        "  else:\n",
        "    lr = 0.001 * tf.math.exp(0.1 * (10 - epoch))\n",
        "  return lr\n",
        "k_learningrate = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wlsh_q4xxG_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "from keras.models import load_model\n",
        "model.load_weights('/content/drive/My Drive/Colab Notebooks/kaggle/steel defect/tmp_10_08.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogxGlV7omYn6",
        "colab_type": "code",
        "outputId": "0b3302d4-8b73-4cb6-8f8f-262df24a2500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=10397//32,  # 2000 images = batch_size * steps\n",
        "      epochs=20,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=2600//32,  # 1000 images = batch_size * steps\n",
        "      callbacks=[k_tensorboard,k_earlystop,k_checkpoint,k_learningrate]\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
            "Epoch 1/20\n",
            "323/324 [============================>.] - ETA: 23s - loss: 2.1670 - acc: 0.4239Epoch 1/20\n",
            " 81/324 [======>.......................] - ETA: 39:18 - loss: 1.7646 - acc: 0.4742\n",
            "Epoch 00001: loss improved from inf to 2.16486, saving model to /content/drive/My Drive/Colab Notebooks/kaggle/steel defect/weights_sets/20200211-044903_CNN.hdf5\n",
            "324/324 [==============================] - 8278s 26s/step - loss: 2.1646 - acc: 0.4233 - val_loss: 1.7646 - val_acc: 0.4742\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
            "Epoch 2/20\n",
            "323/324 [============================>.] - ETA: 23s - loss: 1.3673 - acc: 0.4453Epoch 1/20\n",
            " 81/324 [======>.......................] - ETA: 25:13 - loss: 1.2539 - acc: 0.4742\n",
            "Epoch 00002: loss improved from 2.16486 to 1.36739, saving model to /content/drive/My Drive/Colab Notebooks/kaggle/steel defect/weights_sets/20200211-044903_CNN.hdf5\n",
            "324/324 [==============================] - 8026s 25s/step - loss: 1.3674 - acc: 0.4450 - val_loss: 1.2539 - val_acc: 0.4742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hduv5x4CBdPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.save('/content/drive/My Drive/Colab Notebooks/kaggle/steel defect//weights_sets/CNN_200_08_v1.hdf5')\n",
        "\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "plt.figure()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY_81HAOo2vA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}